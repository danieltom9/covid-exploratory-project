{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d4868d6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"covid_part1.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d95ce8b",
   "metadata": {},
   "source": [
    "# Final Project: COVID-19 Dataset\n",
    "## Exploring COVID-19 Data through Modeling\n",
    "## Due Date: Wednesday, November 17th, 11:59 PM\n",
    "## Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with other groups about\n",
    "the project, we ask that you **write your solutions within your own group**. If you do\n",
    "discuss the assignments with others outside of your group please **include their names** at the top\n",
    "of your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a38a22",
   "metadata": {},
   "source": [
    "\n",
    "## This Assignment\n",
    "\n",
    "In this final project, we will investigate COVID-19 data over the past year. This data contains information about COVID-19 case counts, mortalities, vaccination rates, and various other metadata that can assist in modeling various aspects of COVID-19.\n",
    "\n",
    "Through this final project, you will demonstrate your experience with:\n",
    "* Data cleaning and EDA using Pandas\n",
    "* Unsupervised and supervised learning techniques\n",
    "* Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e55c198",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Model and analyze the temporal evolution of COVID-19 mortalities or cases using one unsupervised and one supervised technique of your choice. Interpret your models' results through visualizations, and draw insightful conclusions about the modeling of COVID-19 data.\n",
    "\n",
    "Recall that we studied linear and logistic regression, decision trees, random forests as part of supervised learning (with labels) and clustering, PCA as part of unsupervised learning (without labels). You are free to use any methods that you find suitable to answer the problem at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dbed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook\n",
    "import numpy as np\n",
    "from geopy import *\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import pearsonr\n",
    "import re\n",
    "\n",
    "cases = pd.read_csv('data/time_series_covid19_confirmed_US.csv') # https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv\n",
    "vaccinations = pd.read_csv('data/people_vaccinated_us_timeline.csv') # https://raw.githubusercontent.com/govex/COVID-19/master/data_tables/vaccine_data/us_data/time_series/people_vaccinated_us_timeline.csv\n",
    "counties = pd.read_csv('data/co-est2020.csv', encoding='latin-1') # https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/counties/totals/co-est2020.csv\n",
    "mask_use = pd.read_csv('data/mask-use-by-county.csv') # https://github.com/nytimes/covid-19-data/blob/master/mask-use/mask-use-by-county.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22406ae3",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "<br/><br/><br/>\n",
    "\n",
    "## Question 0: Basic Time Series Modeling\n",
    "\n",
    "We will introduce a few basic modeling techniques using temporally correlated data that you are free to adapt or improve throughout your modeling process if you wish. Answer these questions in their respective cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f863f9de",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question 0a\n",
    "Suppose $\\tilde{x} = [1, x_{t}]$ represents the input to a machine learning function $f_\\theta: \\mathbb{R}^{2} \\rightarrow \\mathbb{R}$, and we wish to predict $x_{t + 1}$ such that $f_\\theta(\\tilde{x}) \\approx x_{t+1}$. You may assume that $t = 0$ corresponds to the start of time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daeaa20",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "i) Is this an example of supervised or unsupervised learning?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q0ai\n",
    "points: 2\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af37c2a9",
   "metadata": {},
   "source": [
    "This would be an example of supervised learning since we are aware of what we want to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49980f33",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "ii) Write the function $x_{t+1}$ explicitly in terms of the model parameters $\\theta = [\\theta_0, \\theta_1]$ and $x_t$ assuming $f$ represents a linear model.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q0aii\n",
    "points: 2\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449ccb4c",
   "metadata": {},
   "source": [
    "$x_{t+1}$ ‚âà $ùëì_{ùúÉ}(ùë•ÃÉ)$ and $ùëì_{ùúÉ}(ùë•ÃÉ)$ is the linear model output for ùë•ÃÉ. \n",
    "\n",
    "From the linear modeling lecture, $ùëì_{ùúÉ}(ùë•ÃÉ)$ = $ùúÉ^{T}$ùë•ÃÉ , so we can conclude that: $ùëì_{ùúÉ}(ùë•ÃÉ)$ ‚âà $x_{t+1}$ = $ùúÉ_{0}$ + $ùúÉ_{1}x_{t}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8b4175",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "iii) Suppose we obtain an optimal $\\hat{\\theta} = [\\hat{\\theta}_0, \\hat{\\theta}_1]$. Derive $x_{t+1}$ in terms of $x_0$, $\\hat{\\theta}_0$ and $\\hat{\\theta}_1$.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q0aiii\n",
    "points: 4\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b121ad4",
   "metadata": {},
   "source": [
    "From the expression $x_{t+1}$ = $ùúÉ_{0}$ + $ùúÉ_{1}x_{t}$ ,   we can find, by using  $\\hat{ùúÉ}_{0}$ and $\\hat{ùúÉ}_{1}$ , the expression of $x_{t+1}$. \n",
    "\n",
    "By calculating $x_{1}$, $x_{2}$, and so on, and finding the pattern, one finds that:\n",
    "\n",
    "\n",
    "$$x_{t+1} = \\sum_{i=0}^t \\hat{ùúÉ}_{1}^{i} \\hat{ùúÉ}_{0} + \\hat{ùúÉ}_{1}^{t+1} x_{0}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1897abfb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "iv) Suppose we add $k - 1$ more features such that our feature vector $\\tilde{x}$ contains $k$ timesteps of past and current data. Describe how we could select an appropriate $k$.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q0aiv\n",
    "points: 2\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf54538",
   "metadata": {},
   "source": [
    "In this case, k is a hyperparameter. It‚Äôs usually up to us what k value we decide to choose but the best k value can be determined through cross-validation. With cross-validation, the k value that leads to the best model performance can be found without overfitting or underfitting the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041c73f6",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "<br/><br/><br/>\n",
    "\n",
    "## Question 1: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1b113b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1a\n",
    "\n",
    "Investigate the number of missing or null values in `cases` and `vaccinations`. Which one column contains the *most* null values from both of these tables?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db289d60-e1f9-4558-b8af-aba8fbc89c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8ba71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = vaccinations.isna().sum().sort_values(ascending=False).head(1)\n",
    "c = cases.isna().sum().sort_values(ascending=False).head(1)\n",
    "most_null_value_col = \"People_Partially_Vaccinated\"\n",
    "most_null_value_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947fa1c9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2be83ed",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1b\n",
    "\n",
    "Impute the null values in *all* the datasets with zero values or empty strings where appropriate.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1b\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6e0eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "vaccinations = vaccinations.fillna(0)\n",
    "cases = cases.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6b6115",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d357613",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1c\n",
    "\n",
    "Add a column to `cases` named `median_increase` that describes the median daily increase in the number of cases over the time period January 23, 2020 to September 12, 2021. In other words, calculate the increase in cases day-to-day from January 22nd to 23rd, 23rd to 24th, 24th to 25th, and so on; then, find the median of the number of increase in cases over that time period for all counties.\n",
    "\n",
    "*Hint*: Try not to use a `for` loop.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1c\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb17fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_in_time = cases.loc[:, '1/23/20' : '9/12/21']\n",
    "diff = cases_in_time.diff(axis = 1).fillna(0)\n",
    "median_diff = np.median(diff, axis = 1)\n",
    "cases['median_increase'] = median_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d68907",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86811c7a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1d\n",
    "\n",
    "Generate a valid FIPS code for the `counties` table.\n",
    "\n",
    "*Hint*: Refer to [this](https://transition.fcc.gov/oet/info/maps/census/fips/fips.txt) guide on FIPS codes.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1d\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef06e930",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_code = counties['STATE']\n",
    "sc_str = state_code.map('{:02}'.format).astype(str)\n",
    "county_code = counties['COUNTY']\n",
    "cc_str = county_code.map('{:03}'.format).astype(str)\n",
    "FIPS = sc_str + cc_str\n",
    "counties['FIPS'] = FIPS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad33e35",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8067cc79",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1e\n",
    "\n",
    "Merge the `counties`, `cases`, and `mask_use` tables on an appropriate primary key to generate county-wise data.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1e\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2366b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "counties['PK'] = counties['FIPS'].astype(int)\n",
    "cases['PK'] = cases['FIPS'].astype(int)\n",
    "\n",
    "county_data = pd.merge(pd.merge(counties, cases, on = 'PK', how = 'inner'), \n",
    "                       mask_use, left_on='PK', right_on='COUNTYFP', how = 'inner')\n",
    "\n",
    "county_data = county_data.drop(columns = ['PK', 'FIPS_y'])\n",
    "county_data = county_data.rename({'FIPS_x': 'FIPS'}, axis = 'columns')\n",
    "cases = cases.drop(columns = 'PK')\n",
    "counties = counties.drop(columns= 'PK')\n",
    "                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe96ba5d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55aadcf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 1f\n",
    "\n",
    "Generate the population by state using `counties` using the population estimate in 2020 (i.e. `POPESTIMATE2020`). Remark on any inconsistencies and propose a solution. \n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1f\n",
    "points: 2\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9af13e6-1739-4e96-8cd5-63c36354d103",
   "metadata": {},
   "outputs": [],
   "source": [
    "counties[counties['STNAME'] == counties['CTYNAME']][['STNAME', 'CTYNAME', 'POPESTIMATE2020']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b63ded8",
   "metadata": {},
   "source": [
    "If we look closely at the counties table, we can observe that for each state, the rows contain the total population of that state. If both the 'STNAME' and 'CTYNAME' columns have the names of the states, then the 'POPESTIMATE2020' column will have the total population for the state in 2020. This means that if we were to apply functions like groupby to the table, then the final results will be incorrect. Results will likely be 2x the actual population and won't be able to generate accurate population counts. Also, there are 52 rows, despite there being 50 states, because District of Columbia has two rows dedicated to it. \n",
    "\n",
    "Possible solutions I would recommend include: dropping the two rows for District of Columbia and dropping 'CTYNAME' column. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741bf86e",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "<br/><br/><br/>\n",
    "\n",
    "## Question 2: Guided EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862404d4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 2a\n",
    "\n",
    "Create a visualization that shows the median increase in number of cases for the 50 counties with the greatest median increase over January 23, 2020 to September 12, 2021. Make sure to include the name of state in which each county is located since county names are not necessarily unique.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2a\n",
    "points: 3\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a5bb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2a = cases[['Combined_Key', 'median_increase']].sort_values(by='median_increase', ascending=False).head(50)\n",
    "plt.figure(figsize = (10, 10))\n",
    "plt.barh(y='Combined_Key', width='median_increase', data = p2a)\n",
    "plt.xlabel('Median Increase')\n",
    "plt.ylabel('Combined_Key')\n",
    "plt.title('Top 50 Counties in the US by Median Increase in Covid 19')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f79760",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 2b\n",
    "\n",
    "Create a visualization that shows the overall county-wise distribution of the number of COVID-19 cases per capita across the United States as a function of time. For all questions that reference population, use the population estimates from 2020.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2b\n",
    "points: 4\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8d6b98-e70f-4af8-b775-2b3f068237bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "counties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21642f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking a time frame of 9 months from 1st January 2021 to 12th September 2021 \n",
    "#We make cases of covid19 per capita\n",
    "daily_cases = county_data.loc[:,'1/1/21':'9/12/21']\n",
    "pop_per_county = county_data['POPESTIMATE2020']\n",
    "per_capita = daily_cases.div(pop_per_county, axis=0)\n",
    "\n",
    "#boxplot\n",
    "ax = sns.boxplot(data=per_capita, showfliers=False)\n",
    "plt.title('Overall County-Wise Distribution of COVID-19 Cases per Capita Over Time')\n",
    "plt.ylabel('COVID-19 Cases per Capita')\n",
    "plt.xlabel('Date');\n",
    "plt.rcParams['figure.figsize'] = (20, 12)\n",
    "plt.rcParams['font.size'] = 18\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(10))\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d12eed",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 2c\n",
    "\n",
    "Create a visualization that shows states' increases in the number of COVID-19 cases per capita from September 3rd to September 12th, sorted from least to greatest increases. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2c\n",
    "points: 3\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26063e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2c = cases.groupby('Province_State').sum()\n",
    "statePopEst = counties.groupby('STNAME').sum()[['POPESTIMATE2020']]\n",
    "p2c = p2c.merge(statePopEst, left_index =True, right_on = 'STNAME')\n",
    "p2c = p2c.loc[:, '9/3/21': '9/12/21'].div(p2c['POPESTIMATE2020'], axis = 0)\n",
    "p2c = (p2c['9/12/21'] - p2c['9/3/21']).sort_values(ascending=False)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.xlabel('Increase in number of cases per capita from 9/3/21 - 9/12/21')\n",
    "plt.ylabel('State')\n",
    "plt.title('States ordered by the increase in number of cases from 9/3/21 - 9/12/21')\n",
    "p2c.plot.barh()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44f54f7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 2d\n",
    "\n",
    "Create a plot using a technique of your choice that visualizes the relationship between:\n",
    "\n",
    "a) the number of COVID-19 cases as a function of time for the Mobile, Tarrant, Cook, and San Fransisco counties located in Alabama, Texas, Illinois, and California.\n",
    "\n",
    "b) the frequency of never, rarely or sometimes wearing a mask in the respective counties\n",
    "\n",
    "*Hint*: You may find a description of the data [here](https://github.com/CSSEGISandData/COVID-19/blob/846fa9458cc2a8904d2492d14d3e6b4f399ec027/csse_covid_19_data/csse_covid_19_time_series/README.md).\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2d\n",
    "points: 3\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83175649",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2d = cases.where(cases['Admin2'].isin(['Mobile', 'Tarrant', 'Cook', 'San Francisco'])).dropna()\n",
    "p2da = p2d.where(p2d['Province_State'].isin(['Alabama', 'Texas', 'Illinois', 'California'])).dropna().set_index('Admin2')\n",
    "p2da = p2da.loc[:, '1/22/20':'9/12/21'].T\n",
    "p2da.index = pd.to_datetime(p2da.index)\n",
    "p2db = p2d.merge(mask_use, left_on='FIPS', right_on='COUNTYFP')\n",
    "p2db['N/R/S'] = p2db['NEVER'] + p2db['RARELY'] + p2db['SOMETIMES'] \n",
    "\n",
    "figure, axes = plt.subplots(2, 1)\n",
    "figure.tight_layout()\n",
    "p2da.plot(figsize=(7, 10), ax=axes[0])\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Number of cases')\n",
    "axes[0].set_title('Number of COVID 19 Cases over time')\n",
    "\n",
    "axes[1] = plt.barh(y='Admin2', width='N/R/S', data=p2db)\n",
    "axes[1] = plt.title('Frequency of Never/Rarely/Sometimes Wearing a Mask for 4 Counties')\n",
    "\n",
    "axes[1] = plt.xlabel('Frequency of Never/Rarely/ Sometimes Wearing a Mask')\n",
    "axes[1] = plt.ylabel('County')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf4427b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 2e\n",
    "\n",
    "Visualize and describe the spatial relationship between the location and the following quantities over the continguous United States:\n",
    "\n",
    "a) the number of most recent COVID-19 cases per capita on September 12, 2021\n",
    "\n",
    "b) the frequency of never, rarely or sometimes wearing a mask\n",
    "\n",
    "*Hint*: Use `plotly` to generate a heatmap on a geographical plot of the United States!\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2e\n",
    "points: 5\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e67510-6884-466a-b04d-a3bb9b8157da",
   "metadata": {},
   "outputs": [],
   "source": [
    "popEst = counties[['POPESTIMATE2020', 'FIPS']]\n",
    "popEst['FIPS'] = popEst['FIPS'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b12a958-9ad9-45e0-9670-1d3700533841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    countiesjson = json.load(response)\n",
    "\n",
    "p2e = cases.merge(popEst, on='FIPS')\n",
    "p2e = p2e.merge(mask_use, left_on = 'FIPS', right_on='COUNTYFP')\n",
    "p2e.loc[:, '1/22/20':'9/12/21'] = p2e.loc[:, '1/22/20':'9/12/21'].div(p2e['POPESTIMATE2020'], axis=0)\n",
    "p2e['N/R/S'] = p2e['NEVER'] + p2e['RARELY'] + p2e['SOMETIMES']\n",
    "p2e['FIPS'] = p2e['FIPS'].astype(int).astype(str).str.zfill(5)\n",
    "p2e = p2e[~p2e['Province_State'].isin(['Alaska', 'Hawaii'])]\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"choropleth\"},{\"type\": \"choropleth\"}],])\n",
    "fig.add_trace(go.Choropleth(geojson=countiesjson, colorscale=\"Viridis\", locations=p2e['FIPS'], z=p2e['N/R/S'], colorbar_x=0.45,\n",
    "                           name='Frequency of Never/Rarely/Sometimes wearing a Mask'), row=1, col=1)\n",
    "fig.add_trace(go.Choropleth(geojson=countiesjson, colorscale=\"Viridis\", locations=p2e['FIPS'], z=p2e['9/12/21']-p2e['9/11/21'], zmin=(p2e['9/12/21']-p2e['9/11/21']).min(),\n",
    "                           zmax=(p2e['9/12/21']-p2e['9/11/21']).max()-.001, name='Cases on 9/12/21 per capita'), row=1, col=2)\n",
    "fig.update_geos(fitbounds=\"locations\", visible=False)\n",
    "fig.update_layout(title='Frequency of Never/Rarely/Sometimes wearing a Mask vs Number of COVID cases per capita on 9/12/21')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19076b32",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 2f\n",
    "\n",
    "Describe and interpret the relationships in the plots above. What conclusions can be drawn about the COVID-19 dataset from these plots?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2f\n",
    "points: 3\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba3b47c",
   "metadata": {},
   "source": [
    "Looking at the two heatmaps above, there appears to be a correlation between amount of covid cases per capita and frequency of mask usage. From the plots, we can infer that lower mask usage is related to higher covid case rates. However, the plot we generated in 2d appears to suggest something different. Despite Mobile's lower mask usage , their number of covid cases was low, similar to San Francisco's covid rate - despite San Francisco's higher mask usage. We can also observe that the growth rate of covid cases in counties displayed a normal distribution with a slight skew right. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8caca2",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "<br/><br/><br/>\n",
    "\n",
    "## Question 3: Guided Unsupervised Exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e706bb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 3a\n",
    "\n",
    "Using SVD, decompose the standardized matrix $X$ that contains the standardized current proportion of fully vaccinated and partially vaccinated, cases per capita, and mask usage for every state as of the most recent day in the data.\n",
    "\n",
    "*Hint*: The matrix $X$ should have rows that describe location.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3a\n",
    "points: 3\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32694741-feb7-480d-905d-6f0c25ca3627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the latest possible date with vaccination info and cases info\n",
    "vaccinations_latest = vaccinations[vaccinations['Date'] == '2021-09-12']\n",
    "\n",
    "# Merge county_data and vaccination data\n",
    "wanted_cols = ['STNAME', 'POPESTIMATE2020', 'People_Fully_Vaccinated', 'People_Partially_Vaccinated', '9/12/21',\n",
    "               'NEVER' , 'RARELY', 'SOMETIMES', 'FREQUENTLY', 'ALWAYS', 'Long__y', 'Lat_y']\n",
    "merged = pd.merge(county_data, vaccinations_latest, how='inner', left_on=\"STNAME\", right_on=\"Province_State\")[wanted_cols]\n",
    "\n",
    "# Calculate the absolute number of mask usage rather than proportion\n",
    "for col_name in ('NEVER' , 'RARELY', 'SOMETIMES', 'FREQUENTLY', 'ALWAYS'):\n",
    "    merged[\"{}_ABS\".format(col_name)] = merged[col_name] * merged[\"POPESTIMATE2020\"]\n",
    "\n",
    "# Group by state. Everything should be added except for vaccination info and long/lat since that info is by state\n",
    "by_state = merged.groupby(\"STNAME\").agg({\"POPESTIMATE2020\": \"sum\", \"People_Fully_Vaccinated\": \"first\", \"People_Partially_Vaccinated\": \"first\",\n",
    "                              \"9/12/21\": \"sum\", \"NEVER_ABS\": \"sum\", \"RARELY_ABS\": \"sum\", \"SOMETIMES_ABS\": \"sum\",\n",
    "                              \"FREQUENTLY_ABS\": \"sum\", \"ALWAYS_ABS\": \"sum\", \"Long__y\": \"first\", \"Lat_y\": \"first\"})\n",
    "\n",
    "# Now that everything's summed, we can calculate mask usage proportions again\n",
    "for col_name in ('NEVER' , 'RARELY', 'SOMETIMES', 'FREQUENTLY', 'ALWAYS'):\n",
    "    col_name_abs = col_name + '_ABS'\n",
    "    by_state[col_name] = by_state[col_name_abs] / by_state['POPESTIMATE2020']\n",
    "\n",
    "# Calculate the cases per capita\n",
    "by_state['cases_per_capita'] = by_state['9/12/21'] / by_state['POPESTIMATE2020']\n",
    "\n",
    "# Calculate proportion of vaccinations\n",
    "by_state['fully_vaccinated_proportion'] = by_state['People_Fully_Vaccinated'] / by_state['POPESTIMATE2020']\n",
    "by_state['partially_vaccinated_proportion'] = by_state['People_Partially_Vaccinated'] / by_state['POPESTIMATE2020']\n",
    "\n",
    "# Select only the columns we want\n",
    "standardized_matrix = by_state[['fully_vaccinated_proportion', 'partially_vaccinated_proportion', 'cases_per_capita', 'NEVER', 'RARELY', 'SOMETIMES', 'FREQUENTLY', 'ALWAYS']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742ced3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = standardized_matrix\n",
    "X_mean = np.mean(X, axis=0)\n",
    "X_std = np.std(X, axis=0)\n",
    "X = (X - X_mean) / X_std\n",
    "u, s, vt = np.linalg.svd(X, full_matrices = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282a932a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 3b\n",
    "\n",
    "Visualize the top 2 principal components and label the data points with the corresponding location. Color each data points based on the number of cases per capita in the location to which it corresponds.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3b\n",
    "points: 3\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949c91bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pcs = pd.DataFrame(np.matmul(u, np.diag(s)))\n",
    "X_pcs = X_pcs.rename(columns = {0: 'pc1', 1: 'pc2'})\n",
    "\n",
    "#Add back columns for visualization\n",
    "X_pcs['cases_per_capita'] = list(standardized_matrix['cases_per_capita'])\n",
    "X_pcs['state'] = list(by_state.index)\n",
    "\n",
    "#Plot\n",
    "sns.set(rc = {'figure.figsize': (15, 10)})\n",
    "\n",
    "ax = sns.scatterplot(data = X_pcs, x = 'pc1', y = 'pc2', palette = 'RdBu_r', hue = 'cases_per_capita', s = 50)\n",
    "for line in range(0, X_pcs.shape[0]): \n",
    "    ax.text(X_pcs.pc1[line]+0.1, X_pcs.pc2[line],\n",
    "    X_pcs.state[line], horizontalalignment='left', size='medium', color='black')\n",
    "plt.legend(bbox_to_anchor=(1.21, 1), title='Cases Per Capita'); \n",
    "plt.title('First 2 Principal Components of Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a62362",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 3c\n",
    "\n",
    "What could the first and second principal component roughly represent? Interpret the visualization above and report any findings from the first two principal components given by PCA.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3c\n",
    "points: 3\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a9dad2",
   "metadata": {},
   "source": [
    "PC1 and PC2 together both seem to roughly represent cases per capita. We have to look at them together since states with low cases per capita seem to be all located in a single \"quadrant\" of the plot above rather than a vertical split or horizontal split. States with a high PC1 and high PC2 tend to have lower cases per capita while other combinations of high/low values for PC1 and PC2 all seem to have a relatively high proportion of cases per capita."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99515479",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 3d\n",
    "\n",
    "Construct a scree plot displaying the proportion of variance captured by each principal component.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3d\n",
    "points: 3\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800f4bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculations of proportions of variance taken directly from hw10\n",
    "sns.set(rc = {'figure.figsize': (8,5)})\n",
    "plt.plot([i for i in range(1, len(s) + 1)], s**2 / sum(s**2)); \n",
    "plt.xticks([i for i in range(1, len(s) + 1)], [i for i in range(1, len(s) + 1)]);\n",
    "\n",
    "plt.xlabel('PC #'); \n",
    "plt.ylabel('Fraction of Variance Explained'); \n",
    "plt.title('Fraction of Variance Explained by each Principal Component'); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a891ace",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Question 3e\n",
    "\n",
    "Using the 2D representation of each state's first two principal components $x_i = [\\text{PC}_1, \\text{PC}_2]$, find each state's 5 closest principal component neighbors using Euclidean distance as the metric. In other words, for each state $i$ with first two principal components $x_i$, the following would be its *closest* principal component neighbor:\n",
    "\n",
    "$$\n",
    "\\arg \\min_{j \\ne i} ||x_j - x_i||_2\n",
    "$$\n",
    "\n",
    "Store each state's 5 closest neighbors in a Pandas DataFrame, where the index is the state's name and the columns are the 5 closest PC neighbors.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3e\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75d3517-78e3-4575-9b0b-6ac7fa7eff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_12(df, state1, state2): \n",
    "    state1_row = df[df['state'] == state1]\n",
    "    state2_row = df[df['state'] == state2]\n",
    "    state1_pc1 = state1_row.iloc[0]['pc1']\n",
    "    state1_pc2 = state1_row.iloc[0]['pc2']\n",
    "    state2_pc1 = state2_row.iloc[0]['pc1']\n",
    "    state2_pc2 = state2_row.iloc[0]['pc2']\n",
    "    squared_euc_dist = (state2_pc1 - state1_pc1) ** 2 + (state2_pc2 - state1_pc2) ** 2\n",
    "    return squared_euc_dist ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cbdbf9-16d8-4bd7-b454-96070d91ed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate over all the states for their closest neighbors\n",
    "results = [[] for i in range(5)]\n",
    "\n",
    "for state1 in X_pcs['state']:\n",
    "    l2_scores = []\n",
    "    for state2 in X_pcs['state']: \n",
    "        if state1 != state2: \n",
    "            l2_score = calc_12(X_pcs, state1, state2)\n",
    "            l2_scores.append((state2, l2_score))\n",
    "    l2_scores.sort(key=lambda x: x[1])\n",
    "    for i in range(5): \n",
    "        results[i].append(l2_scores[i][0])\n",
    "top_5_closest = pd.DataFrame({'state': list(X_pcs['state']), \n",
    "                              '1': results[0], \n",
    "                              '2': results[1], \n",
    "                              '3': results[2], \n",
    "                              '4': results[3], \n",
    "                              '5': results[4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea2cd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_mins = top_5_closest.set_index('state')\n",
    "state_mins.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35d72a7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79afbc49",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 3f\n",
    "\n",
    "Investigate the principal component neighbors for two states of your choice, and remark on any observations you have about their COVID-19 statistics given in the dataset, geographical or political ties. \n",
    "\n",
    "Compare these neighbors with the rankings from the visualization from Question 2c that depicted recent greatest increases in cases across states.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3f\n",
    "points: 3\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f75c29",
   "metadata": {},
   "source": [
    "By observing the PC neighbors of Alabama, we can see that they all have relatively higher proportions of covid cases per capita. Also, geographically, Alabama's PC neighbors are also all close to Alabama, with Mississipi and Tennessee directly bordering Alabama. Also, similar to Alabama, all of its PC neighbors are generally more conservative leaning states. \n",
    "\n",
    "By observing the PC neighbors of California, we can see that they all have slightly above average proportions of covid cases per capita. However, unlike Alabama, not all of California's PC neighbors are geographically close to California. For instance, while Arizona and Nevada are close to California, Texas, Pennsylvania, and Delaware are not geographically similar at all to California. Also, unlike Alabama, the political affiliations of California's PC neighbors are not homogenous. For example, California and Delaware are generally democratic-leaning, however, states like Texas is usually republican and Arizona and Pennsylvania are swing states. \n",
    "\n",
    "If we compare the rankings from 2c, then we see that for Alabama, a lot of its closest PC neighbors are somewhat near it in terms of rankings in increases in cases across states. This is also somewhat the case with California, with the exception being Delaware with Delaware being quite far from California in terms of rankings. What's quite interesting is that Delaware is closest to California in terms of PC neighbors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbcc4ba",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Question 3g\n",
    "\n",
    "We will investigate the relationship between geographical distance in miles and top two principal component distance between any two unique pairs of states. \n",
    "\n",
    "For the sake of simplicity, may assume that the singular geographical location of a state is given by the mean latitude and longitude of all the counties in that state. For each unique pair of states, calculate the geographical distance and the Euclidean distance between their top 2 principal components between them. Plot the relationship where the x-axis represents the top 2 principal component distance and the y-axis represents geographical distance.\n",
    "\n",
    "*Hint*: `geopy` has a function that can calculate distance between two pairs of latitude and longitude!\n",
    "\n",
    "*Hint*: You should be plotting 1,275 points.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3g\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caf32fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy import distance\n",
    "\n",
    "#reassign long and lat \n",
    "X_pcs['long'] = list(by_state['Long__y'])\n",
    "X_pcs['lat'] = list(by_state['Lat_y'])\n",
    "\n",
    "#Looping through all pairs of states\n",
    "calculated = set()\n",
    "x, y = [], []\n",
    "for state1 in X_pcs['state']: \n",
    "    for state2 in X_pcs['state']: \n",
    "        if state1 != state2: \n",
    "            if (state1, state2) in calculated or (state2, state1) in calculated: \n",
    "                continue\n",
    "            calculated.add((state1, state2))\n",
    "            pc_dist = calc_12(X_pcs, state1, state2)\n",
    "            state1_row = X_pcs[X_pcs['state'] == state1]\n",
    "            state2_row = X_pcs[X_pcs['state'] == state2]\n",
    "            state1_lon = state1_row.iloc[0]['long']\n",
    "            state1_lat = state1_row.iloc[0]['lat']\n",
    "            state2_lon = state2_row.iloc[0]['long']\n",
    "            state2_lat = state2_row.iloc[0]['lat']\n",
    "            coords_1 = (state1_lat, state1_lon)\n",
    "            coords_2 = (state2_lat, state2_lon)\n",
    "            geo_dist = distance.distance(coords_1, coords_2).miles\n",
    "            x.append(pc_dist)\n",
    "            y.append(geo_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65c9906-e7ed-4f3e-a7a4-1750a3314d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ax = sns.scatterplot(x = x, y = y); \n",
    "plt.xlabel('Principcal Component Distance'); \n",
    "plt.ylabel('Geographic Distance'); \n",
    "plt.title('Principcal Component Distance vs. Geographic Distance'); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3f30eb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3h\n",
    "\n",
    "Interpret the relationship displayed in part (g). What does this suggest about the role that geography plays within this dataset despite no geographical information explicitly encoded within the matrix  $X$ from part (a)?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3h\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa0db52",
   "metadata": {},
   "source": [
    "Looking at this plot, there appears to be a positive linear relationshiop between geographic distance and principal component distance. From this observation, we can infer that geography is correlated to the features we have in our X matrix (vaccination rate, mask usage, cases). However, this result isn't very surprising given the cultural and political differences between all the states. However, I do think it is interesting that we can analyze the effect of geographic distance, despite there not being any data about geographic distance in the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf828e9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "<br/><br/><br/>\n",
    "\n",
    "## Question 4: Open EDA\n",
    "\n",
    "Perform EDA of your choice on the data to generate 2 visualizations. You may follow the line of investigation in the guided sections by visualizing the relationship between safety protocols and the spread of COVID-19 spatially or temporally, or you may explore other areas of your choice. \n",
    "\n",
    "For each visualization, make sure to address the following:\n",
    "\n",
    "1. Address a relationship in the data concerning the spread, effect, or prevention of COVID-19 through a visualization, with at *most* one univariate data visualization. If needed, use an unsupervised learning technique such as PCA to reveal patterns within the data.\n",
    "2. Comment on the visualization in terms of the distribution, trends, and patterns it shows.\n",
    "3. Comment on what the visualization indicates about the data with regards to the features you may choose for a supervised learning task.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4\n",
    "points: 30\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca48fa03-409b-4731-9946-3cee7baa9420",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#A) This visualization attempts to show whether or not there's a relationship between latitude and median change in daily covid\n",
    "#cases from 1/22/20 - 9/12/21 Essentially, we are looking to see if there is a relationship between climate and increases in \n",
    "#covid cases per state (using latitude as a proxy for climate)\n",
    "\n",
    "#B) From the scatterplot, we can see a slight negative correlation between latitude and median change in daily covid cases from\n",
    "#1/22/20 - 9/12/21\n",
    "\n",
    "#C) From this visualization, we could run a linear regression to help predict changes in covid cases. \n",
    "\n",
    "\n",
    "\n",
    "lat_grouped = county_data[['median_increase', 'Lat', 'STNAME']].groupby('STNAME').mean()\n",
    "sns.scatterplot(data = lat_grouped, x = 'median_increase', y = 'Lat', palette = 'RdBu_r', s = 50)\n",
    "x = lat_grouped['median_increase']\n",
    "y = lat_grouped['Lat']\n",
    "z = np.polyfit(x, y, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(x,p(x),\"r--\")\n",
    "plt.title('Latitude vs. Median Increase in Covid Cases Per State')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9913478c-10ac-43f4-8b3b-3366e05da5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A) For this plot, we  wanted to investigate possible trends in mask usage in the counties in the data set.\n",
    "\n",
    "#B) From this box plot, we can see that the largest range in mask usage was in the ‚Äòalways‚Äô category. This maybe reflects the \n",
    "#huge differences in attitude towards covid across the nation - with some counties always wearing masks and others not so much.\n",
    "#Despite this, the four other mask usage categories displayed somewhat similar distributions. Additionally, we can see that in \n",
    "#all the mask usages except 'always', there are many outliers. \n",
    "\n",
    "#C) From this plot, we could possibly use the types of mask usage in a future supervised learning model, such as classification. \n",
    "\n",
    "\n",
    "sns.boxplot(data=mask_use.drop(['COUNTYFP'], axis=1))\n",
    "plt.title('Proportion of Mask Usage in Dataset')\n",
    "plt.xlabel('Frequency of Each Mask Usage')\n",
    "plt.ylabel('Proportion of Types of Mask Usage')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c953f41",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a935b7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc4dbdb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aa7490",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001fcffa",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
